basepath: /Users/tgadfort/Documents/pymva
feature:
  NAstrategy:
    float64: mean
    int64: zero
    object: dummy
  Selection:
    criteria: percentile
    test: chi2
    threshold: 90
  dropList: colData.info
input:
  test: null
  train: train.csv
  valid: test.csv
models:
  classification:
    discrim:
      lda:
        iter: 2
        tune: true
      qda:
        iter: 40
        tune: true
    ensemble:
      adaboost:
        iter: 5
        params:
          learning_rate: genPowerTen(-2, 1, 5)
          n_estimators: 100
        tune: true
      extratrees:
        iter: 10
        params:
          criterion: genList(['gini', 'entropy'])
          max_depth: genList([2, 4, 6, None])
          max_features: genList(['auto', 'sqrt', 'log2', None])
          min_impurity_decrease: genLinear(0.0, 0.25, step=0.05)
          min_samples_leaf: genLinear(1, 10, step=1)
          n_estimators: 50
        tune: true
      gbm:
        iter: 10
        params:
          learning_rate: genPowerTen(-2, -0.5, 4)
          loss: genList(['deviance'])
          max_depth: genList([2, 4, 6, 8])
          n_estimators: 50
        tune: true
      rf:
        iter: 10
        params:
          criterion: genList(['gini', 'entropy'])
          max_depth: genList([2, 4, 6, None])
          max_features: genList(['auto', 'sqrt', 'log2', None])
          min_impurity_decrease: genLinear(0.0, 0.25, step=0.05)
          min_samples_leaf: genLinear(1, 10, step=1)
          n_estimators: 50
        tune: true
      xgboost:
        iter: 20
        params:
          gamma: genLinear(0, 1, step=0.2)
          learning_rate: genPowerTen(-2, -0.5, 4)
          max_depth: genLinear(2, 8, step=2)
          n_estimators: 100
          reg_alpha: genPowerTen(-2, 1, 4)
          reg_lambda: genPowerTen(-2, 1, 4)
        tune: true
    gaussian:
      gaussproc:
        error: true
        tune: false
    linear:
      logistic:
        iter: 18
        params:
          C: genPowerTen(-4, 4, 9)
          penalty: genList(['l1', 'l2'])
        refit: false
        tune: true
      passagg:
        iter: 9
        params:
          C: genPowerTen(-4, 4, 9)
          loss: genList(["hinge", "squared_hinge"])
          max_iter:
          - 1000
          tol:
          - 0.001
        tune: true
      sgd:
        iter: 20
        params:
          alpha: genPowerTen(-4, 4, 9)
          epsilon: genLinear(0.05, 0.25, step=0.05)
          eta0: genPowerTen(-3, -1, 3)
          l1_ratio: genPowerTen(-2, 0, 3)
          learning_rate: genList(["constant", "optimal", "invscaling"])
          loss: genList(["modified_huber", "log"])
          max_iter:
          - 1000
          penalty: genList(['l1', 'l2'])
          power_t: genList([0.125, 0.25, 0.5])
          tol:
          - 0.001
        tune: true
    nb:
      nb:
        tune: false
      nbbern:
        iter: 9
        params:
          alpha: genPowerTen(-4, 4, 9)
        tune: true
      nbmulti:
        error: true
        iter: 9
        params:
          alpha: genPowerTen(-4, 4, 9)
        tune: false
    neighbors:
      kneighbors:
        iter: 10
        params:
          algorithm: genList(['auto', 'ball_tree', 'kd_tree', 'brute'])
          leaf_size: genLinear(10, 50, step=10)
          metric: genList['minkowski', 'cityblock', 'cosine', 'euclidean', 'l1', 'l2',
            'manhattan'])
          n_jobs:
          - -1
          weights: genList(['uniform', 'distance'])
        tune: true
      rneighbors:
        iter: 10
        params:
          algorithm: genList(['auto', 'ball_tree', 'kd_tree', 'brute'])
          leaf_size: genLinear(10, 50, step=10)
          metric: genList['minkowski', 'cityblock', 'cosine', 'euclidean', 'l1', 'l2',
            'manhattan'])
          n_jobs:
          - -1
          radius: genLinear(0.5, 1.5, 3)
          weights: genList(['uniform', 'distance'])
        tune: true
    nn:
      mlp:
        iter: 4
        params:
          activation: genList(["identity", "logistic", "tanh", "relu"])
          alpha: genPowerTen(-4, 4, 9)
          beta_1: genLinear(0.81, 0.99, step=0.04)
          hidden_layer_sizes: genList([(10,), (25,), (50,)])
          max_iter: 500
        tune: true
    svm:
      svmepslinear:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['linear'])
          probability: true
        tune: true
      svmepspoly:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['poly'])
          probability: true
        tune: true
      svmepsrbf:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['rbf'])
          probability: true
        tune: true
      svmepssigmoid:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['sigmoid'])
          probability: true
        tune: true
      svmlin:
        iter: 10
        params:
          C: genPowerTen(-4, 4, 9)
          loss: genList(['epsilon_insensitive', 'squared_epsilon_insensitive'])
        refit: true
        tune: true
      svmnulinear:
        iter: 4
        params:
          kernel: genList(['linear'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        refit: true
        tune: true
      svmnupoly:
        iter: 4
        params:
          coef0: genLinear(-1, 1, 3)
          degree: genLinear(1, 5, step=1),
          gamma:
          - auto
          kernel: genList(['poly'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        tune: true
      svmnurbf:
        iter: 4
        params:
          gamma:
          - auto
          kernel: genList(['rbf'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        tune: true
      svmnusigmoid:
        iter: 4
        params:
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['sigmoid'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        tune: true
    tree:
      dtree:
        iter: 20
        params:
          criterion: genList(['gini', 'entropy'])
          max_depth: genList([2, 4, 6, None])
          max_features: genList(['auto', 'sqrt', 'log2', None])
          min_impurity_decrease: genLinear(0.0, 0.25, step=0.05)
          min_samples_leaf: genLinear(1, 10, step=1)
        tune: true
  regression:
    ensemble:
      adaboost:
        iter: 5
        params:
          learning_rate: genPowerTen(-2, 1, 5)
          n_estimators: 100
        tune: true
      extratrees:
        iter: 10
        params:
          criterion: genList(['gini', 'entropy'])
          max_depth: genList([2, 4, 6, None])
          max_features: genList(['auto', 'sqrt', 'log2', None])
          min_impurity_decrease: genLinear(0.0, 0.25, step=0.05)
          min_samples_leaf: genLinear(1, 10, step=1)
          n_estimators: 50
        tune: true
      gbm:
        iter: 10
        params:
          learning_rate: genPowerTen(-2, -0.5, 4)
          loss: genList(['deviance'])
          max_depth: genList([2, 4, 6, 8])
          n_estimators: 50
        tune: true
      rf:
        iter: 10
        params:
          criterion: genList(['gini', 'entropy'])
          max_depth: genList([2, 4, 6, None])
          max_features: genList(['auto', 'sqrt', 'log2', None])
          min_impurity_decrease: genLinear(0.0, 0.25, step=0.05)
          min_samples_leaf: genLinear(1, 10, step=1)
          n_estimators: 50
        tune: true
      xgboost:
        iter: 20
        params:
          gamma: genLinear(0, 1, step=0.2)
          learning_rate: genPowerTen(-2, -0.5, 4)
          max_depth: genLinear(2, 8, step=2)
          n_estimators: 100
          reg_alpha: genPowerTen(-2, 1, 4)
          reg_lambda: genPowerTen(-2, 1, 4)
        tune: true
    external:
      earth:
        tune: false
      tpot:
          params:
            cv: 2
            generations: 4
            max_time_mins: 100
            njobs: -1
            verbosity: 2
          tune: false
    gaussian:
      gaussproc:
        error: true
        tune: false
    linear:
      ard:
        iter: 10
        params:
          alpha_1: genPowerTen(-8, -4, 9)
          alpha_2: genPowerTen(-8, -4, 9)
          lambda_1: genPowerTen(-8, -2, 13)
          lambda_2: genPowerTen(-8, -2, 13)
        tune: true
      bayesridge:
        iter: 20
        params:
          alpha_1: genPowerTen(-8, -4, 9)
          alpha_2: genPowerTen(-8, -4, 9)
          lambda_1: genPowerTen(-8, -2, 13)
          lambda_2: genPowerTen(-8, -2, 13)
        tune: true
      elasticnet:
        cv: true
        iter: 20
        params:
          alpha: genPowerTen(-4, 4, 9)
          l1_ratio: genPowerTen(-2, 0, 3)
        tune: true
      huber:
        iter: 20
        params:
          alpha: genPowerTen(-4, 4, 9)
          epsilon: genLinear(1.05, 1.65, step=0.05)
          max_iter: 1000
          tol: 0.001
        tune: true
      lasso:
        cv: true
        iter: 9
        params:
          alpha: genPowerTen(-4, 4, 9)
        tune: true
      linear:
        tune: false
      omp:
        cv: true
        tune: false
      passagg:
        iter: 9
        params:
          C: genPowerTen(-4, 4, 9)
          loss: genList(["epsilon_insensitive", "squared_epsilon_insensitive"])
          max_iter:
          - 1000
          tol:
          - 0.001
        tune: true
      ransac:
        tune: false
      ridge:
        cv: false
        iter: 9
        params:
          alpha: genPowerTen(-4, 4, 9)
        tune: true
      sgd:
        iter: 40
        params:
          algorithm: genList(['auto', 'ball_tree', 'kd_tree', 'brute'])
          leaf_size: genLinear(10, 50, step=10)
          loss: genList(["squared_loss", "huber", "epsilon_insensitive", "squared_epsilon_insensitive"])
          metric: genList['minkowski', 'cityblock', 'cosine', 'euclidean', 'l1', 'l2',
            'manhattan'])
          n_jobs:
          - -1
          weights: genList(['uniform', 'distance'])
        tune: true
    neighbors:
      kneighbors:
        iter: 10
        params:
          algorithm: genList(['auto', 'ball_tree', 'kd_tree', 'brute'])
          leaf_size: genLinear(10, 50, step=10)
          metric: genList['minkowski', 'cityblock', 'cosine', 'euclidean', 'l1', 'l2',
            'manhattan'])
          n_jobs:
          - -1
          weights: genList(['uniform', 'distance'])
        tune: true
      rneighbors:
        iter: 10
        params:
          algorithm: genList(['auto', 'ball_tree', 'kd_tree', 'brute'])
          leaf_size: genLinear(10, 50, step=10)
          metric: genList['minkowski', 'cityblock', 'cosine', 'euclidean', 'l1', 'l2',
            'manhattan'])
          n_jobs:
          - -1
          radius: genLinear(0.5, 1.5, 3)
          weights: genList(['uniform', 'distance'])
        tune: true
    nn:
      mlp:
        iter: 4
        params:
          activation: genList(["identity", "logistic", "tanh", "relu"])
          alpha: genPowerTen(-4, 4, 9)
          beta_1: genLinear(0.81, 0.99, step=0.04)
          hidden_layer_sizes: genList([(10,), (25,), (50,)])
          max_iter: 500
        tune: true
    svm:
      svmepslinear:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['linear'])
          probability: true
        tune: true
      svmepspoly:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['poly'])
          probability: true
        tune: true
      svmepsrbf:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['rbf'])
          probability: true
        tune: true
      svmepssigmoid:
        iter: 4
        params:
          C: genPowerTen(-4, 4, 9)
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['sigmoid'])
          probability: true
        tune: true
      svmlin:
        iter: 10
        params:
          C: genPowerTen(-4, 4, 9)
          loss: genList(['epsilon_insensitive', 'squared_epsilon_insensitive'])
        refit: true
        tune: true
      svmnulinear:
        iter: 4
        params:
          kernel: genList(['linear'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        refit: true
        tune: true
      svmnupoly:
        iter: 4
        params:
          coef0: genLinear(-1, 1, 3)
          degree: genLinear(1, 5, step=1),
          gamma:
          - auto
          kernel: genList(['poly'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        tune: true
      svmnurbf:
        iter: 4
        params:
          gamma:
          - auto
          kernel: genList(['rbf'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        tune: true
      svmnusigmoid:
        iter: 4
        params:
          coef0: genLinear(-1, 1, 3)
          gamma:
          - auto
          kernel: genList(['sigmoid'])
          nu: genLinear(0.1, 0.9, step=0.2)
          probability: true
        tune: true
    tree:
      dtree:
        iter: 20
        params:
          criterion: genList(['gini', 'entropy'])
          max_depth: genList([2, 4, 6, None])
          max_features: genList(['auto', 'sqrt', 'log2', None])
          min_impurity_decrease: genLinear(0.0, 0.25, step=0.05)
          min_samples_leaf: genLinear(1, 10, step=1)
        tune: true
name: regression
output:
  compress: true
  name: data.p
performance:
  ext: pdf
  multipage: false
problem: regression
target:
  NAstrategy: zero
  colname: TARGET
  positive: normal.
